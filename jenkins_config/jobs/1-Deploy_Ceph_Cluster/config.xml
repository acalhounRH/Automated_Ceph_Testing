<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <jenkins.model.BuildDiscarderProperty>
      <strategy class="hudson.tasks.LogRotator">
        <daysToKeep>-1</daysToKeep>
        <numToKeep>20</numToKeep>
        <artifactDaysToKeep>-1</artifactDaysToKeep>
        <artifactNumToKeep>-1</artifactNumToKeep>
      </strategy>
    </jenkins.model.BuildDiscarderProperty>
    <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@1.28">
      <autoRebuild>false</autoRebuild>
      <rebuildDisabled>false</rebuildDisabled>
    </com.sonyericsson.rebuild.RebuildSettings>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.TextParameterDefinition>
          <name>ceph_inventory</name>
          <description>Inventory file used to specify ceph cluster</description>
          <defaultValue>[mons]

[osds]

[mgrs]

[mdss]</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>ceph_iso_file</name>
          <description>The RHCS iso to be used for installation.

by default will specify the latest version of RHCS on download site.</description>
          <defaultValue>RHCEPH-3.0-RHEL-7-*-x86_64-dvd.iso</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>ceph_iso_path</name>
          <description>location of the RHCS iso file to be used for installation.

by default will specify the latest version of RHCS on download site.

Example: 

http://download-node-02.eng.bos.redhat.com/composes/auto/ceph-3.0-rhel-7/latest-RHCEPH-3-RHEL-7/compose/OSD/x86_64/iso/</description>
          <defaultValue>http://download-node-02.eng.bos.redhat.com/composes/auto/ceph-3.0-rhel-7/latest-RHCEPH-3-RHEL-7/compose/OSD/x86_64/iso</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>ceph_ansible_all_config</name>
          <description>Contents of the all.yml to be used with ceph-ansible.</description>
          <defaultValue>---
dummy:
fetch_directory: /ceph-ansible-keys
ceph_rhcs_iso_install: true 
ceph_origin: repository
ceph_repository: rhcs
ceph_rhcs_version: 3 
valid_ceph_repository_type:
  - iso
ceph_rhcs_iso_path: $HOME/automated_ceph_test/staging_area/rhcs_latest/$ceph_iso_file
monitor_interface: eth0
journal_size: 5120 # OSD journal size in MB
public_network: 192.168.128.0/17
osd_objectstore: filestore
ceph_conf_overrides:
  mon:
    mon_allow_pool_delete: true</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>ceph_ansible_osds_config</name>
          <description>Contents of the osds.yml to be used with ceph-ansible.</description>
          <defaultValue>---
dummy:
osd_scenario: collocated
devices:
  - /dev/sdc</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
        <org.jvnet.jenkins.plugins.nodelabelparameter.NodeParameterDefinition plugin="nodelabelparameter@1.7.2">
          <name>agentName</name>
          <description></description>
          <allowedSlaves/>
          <defaultSlaves>
            <string>master</string>
          </defaultSlaves>
          <triggerIfResult>multiSelectionDisallowed</triggerIfResult>
          <allowMultiNodeSelection>false</allowMultiNodeSelection>
          <triggerConcurrentBuilds>false</triggerConcurrentBuilds>
          <ignoreOfflineNodes>false</ignoreOfflineNodes>
          <nodeEligibility class="org.jvnet.jenkins.plugins.nodelabelparameter.node.AllNodeEligibility"/>
        </org.jvnet.jenkins.plugins.nodelabelparameter.NodeParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash

echo &quot;test test test&quot;
script_dir=$HOME/automated_ceph_test
inventory_file=$script_dir/ansible_inventory

echo &quot;$ceph_inventory&quot; &gt; $inventory_file
if [ -d /usr/share/ceph-ansible ]; then
	echo &quot;purging cluster and removing previous version of ceph-ansible&quot;
	cd /usr/share/ceph-ansible
	ansible-playbook infrastructure-playbooks/purge-cluster.yml -i $inventory_file -e ireallymeanit=yes
fi

sudo yum remove ceph-ansible -y

#clearout ceph-ansible staging area 

if [ ! -d $script_dir/staging_area/rhcs_latest/ ]; then
	mkdir -p $script_dir/staging_area/rhcs_latest
    mkdir -p $script_dir/staging_area/rhcs_old
    chmod -R 777 $script_dir/staging_area/


else
	mv $script_dir/staging_area/rhcs_latest/* $script_dir/staging_area/rhcs_old/
	pwd
fi
	cd $script_dir/staging_area/rhcs_latest/
	 
sudo rm -rf /ceph-ansible-keys
sudo mkdir -m0777 /ceph-ansible-keys

#pull iso
if [[ $ceph_iso_file =~ &quot;RHCEPH-3.0-RHEL-7-*-x86_64-dvd.iso&quot; ]]; then
	echo &quot;**************$ceph_iso_file&quot;
	sudo wget -r -nd --no-parent -A &quot;$ceph_iso_file&quot; $ceph_iso_path &amp;&gt; /dev/null
    new_ceph_iso_file=&quot;$(ls)&quot;
else
	sudo wget $ceph_iso_path/$ceph_iso_file &amp;&gt; /dev/null
fi
 chmod 777 $ceph_iso_file


#mount ISO and create rhcs yum repo file 
sudo cp $script_dir/staging_area/repo_files/rhcs.repo /etc/yum.repos.d/
sudo mkdir -p /mnt/rhcs_latest/
sudo umount /mnt/rhcs_latest/
sudo mount $script_dir/staging_area/rhcs_latest/RHCEPH* /mnt/rhcs_latest/
sudo yum clean all


#install ceph-ansible
sudo yum install ceph-ansible -y

#added in order to allow installation of bluestore on lVMs
patch /usr/share/ceph-ansible/roles/ceph-osd/tasks/check_mandatory_vars.yml ~/automated_ceph_test/scripts/check_mandatory_vars.patch
patch /usr/share/ceph-ansible/roles/ceph-osd/tasks/scenarios/lvm.yml ~/automated_ceph_test/scripts/lvm.patch


sudo sed -i &apos;s/gpgcheck=1/gpgcheck=0/g&apos; /usr/share/ceph-ansible/roles/ceph-common/templates/redhat_storage_repo.j2

mkdir -p $script_dir/staging_area/tmp
#setup all.yml
echo &quot;$ceph_ansible_all_config&quot; &gt; $script_dir/staging_area/tmp/all.yml
if [[ $ceph_iso_file =~ &quot;RHCEPH-3.0-RHEL-7-*-x86_64-dvd.iso&quot; ]]; then
	sed -i &quot;s/RHCEPH.*$/$new_ceph_iso_file/g&quot; $script_dir/staging_area/tmp/all.yml
fi
sudo cp $script_dir/staging_area/tmp/all.yml /usr/share/ceph-ansible/group_vars/all.yml


#setup osd.yml
echo &quot;$ceph_ansible_osds_config&quot; &gt; $script_dir/staging_area/tmp/osds.yml
sudo cp $script_dir/staging_area/tmp/osds.yml /usr/share/ceph-ansible/group_vars/osds.yml


#copy site.yml
sudo cp /usr/share/ceph-ansible/site.yml.sample /usr/share/ceph-ansible/site.yml

$script_dir/scripts/register_host.sh $inventory_file

echo &quot;Start Ceph installation&quot;
cd /usr/share/ceph-ansible
ANSIBLE_STRATEGY=debug; ansible-playbook site.yml -i $inventory_file


echo &quot;Health check&quot;
$script_dir/scripts/check_cluster_status.sh $inventory_file
exit_status=$?

if [ &quot;$exit_status&quot; -eq &quot;0&quot; ]; then
	#copy client key to all clients
	ceph_client_key=/ceph-ansible-keys/`ls /ceph-ansible-keys/ | grep -v conf`/etc/ceph/ceph.client.admin.keyring
	ansible -m copy -a &quot;src=$ceph_client_key dest=/etc/ceph/ceph.client.admin.keyring&quot; clients -i $inventory_file 
else
	exit 1
fi </command>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <org.jenkinsci.plugins.credentialsbinding.impl.SecretBuildWrapper plugin="credentials-binding@1.16">
      <bindings class="empty-list"/>
    </org.jenkinsci.plugins.credentialsbinding.impl.SecretBuildWrapper>
  </buildWrappers>
</project>