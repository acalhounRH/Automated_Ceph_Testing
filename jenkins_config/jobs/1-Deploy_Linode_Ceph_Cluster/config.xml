<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <jenkins.model.BuildDiscarderProperty>
      <strategy class="hudson.tasks.LogRotator">
        <daysToKeep>-1</daysToKeep>
        <numToKeep>5</numToKeep>
        <artifactDaysToKeep>-1</artifactDaysToKeep>
        <artifactNumToKeep>-1</artifactNumToKeep>
      </strategy>
    </jenkins.model.BuildDiscarderProperty>
    <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@1.28">
      <autoRebuild>false</autoRebuild>
      <rebuildDisabled>false</rebuildDisabled>
    </com.sonyericsson.rebuild.RebuildSettings>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.PasswordParameterDefinition>
          <name>Linode_API_KEY</name>
          <description>Setup a Linode account and get an API key: https://www.linode.com/docs/platform/api/api-key</description>
          <defaultValue>{AQAAABAAAAAQobzpRnmnlxne8VMSMsBjex0tcts6UnYGADChnNwcnpU=}</defaultValue>
        </hudson.model.PasswordParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>Linode_Cluster_Configuration</name>
          <description>Modify to have the desired count and Linode plan for each daemon type.</description>
          <defaultValue>{
  &quot;datacenter&quot;: &quot;Newark&quot;,
  &quot;distribution&quot;: &quot;CentOS 7&quot;,
  &quot;kernel&quot;: 210,
  &quot;nodes&quot;: [
      {
        &quot;count&quot;: 3,
        &quot;prefix&quot;: &quot;mon&quot;,
        &quot;plan&quot;: 1,
        &quot;group&quot;: &quot;mons&quot;
      },
      {
        &quot;count&quot;: 3,
        &quot;prefix&quot;: &quot;osd&quot;,
        &quot;plan&quot;: 1,
        &quot;root_size&quot;: 4096,
        &quot;group&quot;: &quot;osds&quot;
      },
      {
        &quot;count&quot;: 1,
        &quot;prefix&quot;: &quot;mds&quot;,
        &quot;plan&quot;: 1,
        &quot;group&quot;: &quot;mdss&quot;
      },
      {
        &quot;count&quot;: 1,
        &quot;prefix&quot;: &quot;mgr&quot;,
        &quot;plan&quot;: 1,
        &quot;group&quot;: &quot;mgrs&quot;
      },
      {
        &quot;count&quot;: 1,
        &quot;prefix&quot;: &quot;client&quot;,
        &quot;plan&quot;: 1,
        &quot;group&quot;: &quot;clients&quot;
      }
  ]
}</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>ceph_ansible_all_config</name>
          <description>Contents of the all.yml to be used with ceph-ansible.</description>
          <defaultValue>---
dummy:
fetch_directory: /ceph-ansible-keys
ceph_rhcs_iso_install: true 
ceph_origin: repository
ceph_repository: rhcs
ceph_rhcs_version: 3 
valid_ceph_repository_type:
  - iso
ceph_rhcs_iso_path: $HOME/automated_ceph_test/staging_area/rhcs_latest/&lt;ceph_iso_file&gt;
monitor_interface: eth0
journal_size: 5120 # OSD journal size in MB
public_network: 192.168.128.0/17
osd_objectstore: filestore
ceph_conf_overrides:
  mon:
    mon_allow_pool_delete: true</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>ceph_ansible_osds_config</name>
          <description>Contents of the osds.yml to be used with ceph-ansible.</description>
          <defaultValue>---
dummy:
osd_scenario: collocated
devices:
  - /dev/sdc</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
        <org.jvnet.jenkins.plugins.nodelabelparameter.NodeParameterDefinition plugin="nodelabelparameter@1.7.2">
          <name>agentName</name>
          <description></description>
          <allowedSlaves/>
          <defaultSlaves>
            <string>master</string>
          </defaultSlaves>
          <triggerIfResult>multiSelectionDisallowed</triggerIfResult>
          <allowMultiNodeSelection>false</allowMultiNodeSelection>
          <triggerConcurrentBuilds>false</triggerConcurrentBuilds>
          <ignoreOfflineNodes>false</ignoreOfflineNodes>
          <nodeEligibility class="org.jvnet.jenkins.plugins.nodelabelparameter.node.AllNodeEligibility"/>
        </org.jvnet.jenkins.plugins.nodelabelparameter.NodeParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>true</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash


echo &quot;test test test&quot;
systemctl stop firewalld 
systemctl stop iptables
script_dir=$HOME/automated_ceph_test
inventory_file=$HOME/ceph-linode/ansible_inventory

sudo yum remove ceph-ansible -y
rm -rf /usr/share/ceph-ansible

cd $script_dir/staging_area/rhcs_latest/
new_ceph_iso_file=&quot;$(ls)&quot;

sudo rm -rf /ceph-ansible-keys
sudo mkdir -m0777 /ceph-ansible-keys

#mount ISO and create rhcs yum repo file 
sudo cp $script_dir/staging_area/repo_files/rhcs.repo /etc/yum.repos.d/
sudo mkdir -p /mnt/rhcs_latest/
sudo umount /mnt/rhcs_latest/
sudo mount $script_dir/staging_area/rhcs_latest/RHCEPH* /mnt/rhcs_latest/
sudo yum clean all


#install ceph-ansible
sudo yum install ceph-ansible -y

sudo sed -i &apos;s/gpgcheck=1/gpgcheck=0/g&apos; /usr/share/ceph-ansible/roles/ceph-common/templates/redhat_storage_repo.j2

mkdir -p $script_dir/staging_area/tmp
#setup all.yml
echo &quot;$ceph_ansible_all_config&quot; &gt; $script_dir/staging_area/tmp/all.yml
sed -i &quot;s/&lt;ceph_iso_file&gt;/$new_ceph_iso_file/g&quot; $script_dir/staging_area/tmp/all.yml
sudo cp $script_dir/staging_area/tmp/all.yml /usr/share/ceph-ansible/group_vars/all.yml


#setup osd.yml
echo &quot;$ceph_ansible_osds_config&quot; &gt; $script_dir/staging_area/tmp/osds.yml
sudo cp $script_dir/staging_area/tmp/osds.yml /usr/share/ceph-ansible/group_vars/osds.yml


#copy site.yml
sudo cp /usr/share/ceph-ansible/site.yml.sample /usr/share/ceph-ansible/site.yml


#Start Ceph-linode deployment
cd $HOME/ceph-linode
echo &quot;$Linode_Cluster_Configuration&quot; &gt; cluster.json
virtualenv-2 linode-env &amp;&amp; source linode-env/bin/activate &amp;&amp; pip install linode-python
export LINODE_API_KEY=$Linode_API_KEY

ANSIBLE_STRATEGY=debug; ./launch.sh --ceph-ansible /usr/share/ceph-ansible
#sudo ansible -i ansible_inventory -m shell -a &quot;ceph -s&quot; mon-000


#Health check
$script_dir/scripts/check_cluster_status.sh $inventory_file
exit_status=$?

exit $exit_status</command>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers/>
</project>