<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <jenkins.model.BuildDiscarderProperty>
      <strategy class="hudson.tasks.LogRotator">
        <daysToKeep>-1</daysToKeep>
        <numToKeep>5</numToKeep>
        <artifactDaysToKeep>-1</artifactDaysToKeep>
        <artifactNumToKeep>-1</artifactNumToKeep>
      </strategy>
    </jenkins.model.BuildDiscarderProperty>
    <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@1.28">
      <autoRebuild>false</autoRebuild>
      <rebuildDisabled>false</rebuildDisabled>
    </com.sonyericsson.rebuild.RebuildSettings>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.PasswordParameterDefinition>
          <name>Linode_API_KEY</name>
          <description>Setup a Linode account and get an API key: https://www.linode.com/docs/platform/api/api-key</description>
          <defaultValue>{AQAAABAAAAAQobzpRnmnlxne8VMSMsBjex0tcts6UnYGADChnNwcnpU=}</defaultValue>
        </hudson.model.PasswordParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>Linode_Cluster_Configuration</name>
          <description>Modify to have the desired count and Linode plan for each daemon type.</description>
          <defaultValue>[
  {
    &quot;count&quot;: 3,
    &quot;prefix&quot;: &quot;mon&quot;,
    &quot;plan&quot;: 1,
    &quot;group&quot;: &quot;mons&quot;
  },
  {
    &quot;count&quot;: 3,
    &quot;prefix&quot;: &quot;osd&quot;,
    &quot;plan&quot;: 1,
    &quot;root_size&quot;: 4096,
    &quot;group&quot;: &quot;osds&quot;
  },
  {
    &quot;count&quot;: 1,
    &quot;prefix&quot;: &quot;mgr&quot;,
    &quot;plan&quot;: 1,
    &quot;group&quot;: &quot;mgrs&quot;
  },
  {
    &quot;count&quot;: 1,
    &quot;prefix&quot;: &quot;client&quot;,
    &quot;plan&quot;: 1,
    &quot;group&quot;: &quot;clients&quot;
  }
]</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>ceph_iso_file</name>
          <description>The RHCS iso to be used for installation.

by default will specify the latest version of RHCS on download site.</description>
          <defaultValue>RHCEPH-3.0-RHEL-7-*-x86_64-dvd.iso</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.StringParameterDefinition>
          <name>ceph_iso_path</name>
          <description>location of the RHCS iso file to be used for installation.

by default will specify the latest version of RHCS on download site.

Example: 

http://download-node-02.eng.bos.redhat.com/composes/auto/ceph-3.0-rhel-7/latest-RHCEPH-3-RHEL-7/compose/OSD/x86_64/iso/</description>
          <defaultValue>http://download-node-02.eng.bos.redhat.com/composes/auto/ceph-3.0-rhel-7/latest-RHCEPH-3-RHEL-7/compose/OSD/x86_64/iso/</defaultValue>
          <trim>false</trim>
        </hudson.model.StringParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>ceph_ansible_all_config</name>
          <description>Contents of the all.yml to be used with ceph-ansible.</description>
          <defaultValue>---
dummy:
fetch_directory: /ceph-ansible-keys
ceph_rhcs_iso_install: true 
ceph_origin: repository
ceph_repository: rhcs
ceph_rhcs_version: 3 
valid_ceph_repository_type:
  - iso
ceph_rhcs_iso_path: /automated_ceph_test/ceph-linode/staging/rhcs_latest/$ceph_iso_file
monitor_interface: eth0
journal_size: 5120 # OSD journal size in MB
public_network: 192.168.128.0/17
osd_objectstore: filestore
ceph_conf_overrides:
  mon:
    mon_allow_pool_delete: true</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>ceph_ansible_osds_config</name>
          <description>Contents of the osds.yml to be used with ceph-ansible.</description>
          <defaultValue>---
dummy:
osd_scenario: collocated
devices:
  - /dev/sdc</defaultValue>
          <trim>false</trim>
        </hudson.model.TextParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash

echo &quot;test test test&quot;
inventory_file=/automated_ceph_test/ceph-linode/ansible_inventory

#clearout ceph-ansible staging area 
mv /automated_ceph_test/staging_area/rhcs_latest/* /automated_ceph_test/staging_area/rhcs_old/
cd /automated_ceph_test/staging_area/rhcs_latest/

sudo rm -rf /ceph-ansible-keys
sudo mkdir -m0777 /ceph-ansible-keys

#pull iso
if [[ $ceph_iso_file =~ &quot;RHCEPH-3.0-RHEL-7-*-x86_64-dvd.iso&quot; ]]; then
	sudo wget -r -nd --no-parent -A &quot;$ceph_iso_file&quot; $ceph_iso_path &gt; /dev/null
    new_ceph_iso_file=&quot;$(ls)&quot;
else
	sudo wget $ceph_iso_path/$ceph_iso_file &gt; /dev/null
fi


#mount ISO and create rhcs yum repo file 
sudo cp /automated_ceph_test/staging_area/repo_files/rhcs.repo /etc/yum.repos.d/
sudo mkdir -p /mnt/rhcs-latest/
sudo umount /mnt/rhcs_latest/
sudo mount /automated_ceph_test/staging_area/rhcs_latest/RHCEPH* /mnt/rhcs_latest/
sudo yum clean all


#install ceph-ansible
sudo yum install ceph-ansible -y

sudo sed -i &apos;s/gpgcheck=1/gpgcheck=0/g&apos; /usr/share/ceph-ansible/roles/ceph-common/templates/redhat_storage_repo.j2

#setup all.yml
echo &quot;$ceph_ansible_all_config&quot; &gt; /automated_ceph_test/staging_area/tmp/all.yml
if [[ $ceph_iso_file =~ &quot;RHCEPH-3.0-RHEL-7-*-x86_64-dvd.iso&quot; ]]; then
	sed -i &quot;s/RHCEPH.*$/$new_ceph_iso_file/g&quot; /automated_ceph_test/staging_area/tmp/all.yml
fi
sudo cp /automated_ceph_test/staging_area/tmp/all.yml /usr/share/ceph-ansible/group_vars/all.yml


#setup osd.yml
echo &quot;$ceph_ansible_osds_config&quot; &gt; /automated_ceph_test/staging_area/tmp/osds.yml
sudo cp /automated_ceph_test/staging_area/tmp/osds.yml /usr/share/ceph-ansible/group_vars/osds.yml


#copy site.yml
sudo cp /usr/share/ceph-ansible/site.yml.sample /usr/share/ceph-ansible/site.yml


#Start Ceph-linode deployment
cd /automated_ceph_test/ceph-linode
echo &quot;$Linode_Cluster_Configuration&quot; &gt; cluster.json
virtualenv-2 linode-env &amp;&amp; source linode-env/bin/activate &amp;&amp; pip install linode-python
export LINODE_API_KEY=$Linode_API_KEY

ANSIBLE_STRATEGY=debug; ./launch.sh --ceph-ansible /usr/share/ceph-ansible
#sudo ansible -i ansible_inventory -m shell -a &quot;ceph -s&quot; mon-000


#Health check
/automated_ceph_test/scripts/check_cluster_status.sh
exit_status=$?

if [ &quot;$exit_status&quot; -eq &quot;0&quot; ]; then
	#copy client key to all clients
	ceph_client_key=/ceph-ansible-keys/`ls /ceph-ansible-keys/ | grep -v conf`/etc/ceph/ceph.client.admin.keyring
	ansible -m copy -a &quot;src=$ceph_client_key dest=/etc/ceph/ceph.client.admin.keyring&quot; clients -i $inventory_file 
else
	exit 1
fi </command>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <org.jenkinsci.plugins.credentialsbinding.impl.SecretBuildWrapper plugin="credentials-binding@1.15">
      <bindings class="empty-list"/>
    </org.jenkinsci.plugins.credentialsbinding.impl.SecretBuildWrapper>
  </buildWrappers>
</project>